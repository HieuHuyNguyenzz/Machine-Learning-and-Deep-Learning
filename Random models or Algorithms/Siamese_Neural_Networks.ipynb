{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Siamese Neural Network\n",
        "\n",
        "## 1. Khái niệm\n",
        "Siamese Neural Network (SNN) là một kiến trúc mạng nơ-ron chứa hai hoặc nhiều mạng con giống hệt nhau. “Giống hệt nhau” ở đây có nghĩa là, chúng có cùng cấu hình với cùng thông số và trọng số. Việc cập nhật các thông số được phản ánh đồng thời trên cả hai mạng con của nó.\n",
        "\n",
        "SNN được sử dụng để tìm sự giống nhau của các dữ liệu đầu (Input Data) vào bằng cách so sánh các vectơ đặc trưng của chúng. Thông thường, một mạng nơ-ron học cách để dự đoán các lớp của một bài toán. Nếu muốn thêm hay bớt các lớp mới, chúng ta phải cập nhật (huấn luyện) lại mạng nơ-ron trên toàn bộ tập dữ liệu (cả dữ liệu mới và cũ). Ngoài ra, các mạng nơ-ron sâu cần một khối lượng lớn dữ liệu để có thể huấn luyện chúng. SNN, theo một cách khác, học cách tìm ra sự giống nhau giữa các Input Data. Vì vậy, nó cho phép chúng ta phân loại các lớp dữ liệu mới mà không cần huấn luyện lại mạng nơ-ron."
      ],
      "metadata": {
        "id": "D6NCL6tpgZ0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Luồng hoạt động\n",
        "Luồng làm việc của SNN như sau:\n",
        "\n",
        "- Chọn một cặp Input Data (trong phạm vi bài này là ảnh) được chọn từ dataset.\n",
        "\n",
        "- Đưa mỗi ảnh qua mỗi Sub-network của SNN để xử lý. Output của các Sub-networks là một Embedding vector.\n",
        "\n",
        "- Tính toán khoảng cách Euclidean giữa 2 Embedding vectors đó.\n",
        "\n",
        "- Một Sigmoid Function có thể được áp trên khoảng cách để đưa ra giá trị Score trong đoạn [0,1], thể hiện mức độ giống nhau giữa 2 Embedding vectors. Score càng gần 1 thì 2 vectors càng giống nhau và ngược lại."
      ],
      "metadata": {
        "id": "KMibhoZ3g9Xn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Ưu điểm và nhược điểm\n",
        "\n",
        "SNN có một số ưu điểm nổi bật như sau:\n",
        "\n",
        "- Lượng dữ liệu cần thiết để huấn luyện SNN là rất ít. Chỉ cần vài Samples là đủ (1-5 samples) huấn luyện SNN. Phương pháp mà nó sử dụng ở đây là One-Shot Learning hoặc Few-Shot Learning. Chính vì cần ít dữ liệu huấn luyện như vậy nên chúng ta cũng không lo lắng việc dữ liệu bị mất cân bằng (Image Imbalance).\n",
        "\n",
        "- Khả năng kết hợp với các bộ phân loại khác cao. Do cơ chế học của SNN khác biệt với các bộ phân lớp thông thường khác, nên chúng ta hoàn toàn có thể kết hợp chúng lại với nhau. Việc làm này thường cho ra kết quả tốt hơn.\n",
        "\n",
        "- Học từ sự tương đồng về ngữ nghĩa: SNN tập trung vào việc học các Features ở các lớp sâu hơn, nơi mà các Features giống nhau được đặt gần nhau. Do đó, nó có thể hiểu được phần nào sự tương đồng về ngữ nghĩa của các Input Data.\n",
        "\n",
        "SNN cũng có những nhược điểm sau:\n",
        "\n",
        "- Thời gian huấn luyện lâu hơn. SNN học theo từng cặp đôi một với nhau nên khả năng học của nó chậm hơn các NN khác.\n",
        "\n",
        "- Không thể hiện xác suất mỗi lớp trong Output. SNN chỉ đưa đưa 1 giá trị Score trong đoạn [0,1], thể hiện sự giống nhau giữa 2 Input Data. Score càng gần 1 thì 2 Input Data càng giống nhau và ngược lại."
      ],
      "metadata": {
        "id": "GpzMRb32hG3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thực nghiệm\n"
      ],
      "metadata": {
        "id": "T0JdOUMDi1UG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBBI22oRfkGl"
      },
      "outputs": [],
      "source": [
        "class SiameseDataset():\n",
        "    def __init__(self,training_csv=None,training_dir=None,transform=None):\n",
        "        # used to prepare the labels and images path\n",
        "        self.train_df=pd.read_csv(training_csv)\n",
        "        self.train_df.columns =[\"image1\",\"image2\",\"label\"]\n",
        "        self.train_dir = training_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        # getting the image path\n",
        "        image1_path=os.path.join(self.train_dir,self.train_df.iat[index,0])\n",
        "        image2_path=os.path.join(self.train_dir,self.train_df.iat[index,1])\n",
        "        # Loading the image\n",
        "        img1 = Image.open(image1_path)\n",
        "        img2 = Image.open(image2_path)\n",
        "        img1 = img0.convert(\"L\")\n",
        "        img2 = img1.convert(\"L\")\n",
        "        # Apply image transformations\n",
        "        if self.transform is not None:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "        return img1, img2 , th.from_numpy(np.array([int(self.train_df.iat[index,2])],dtype=np.float32))\n",
        "    def __len__(self):\n",
        "        return len(self.train_df)\n",
        "\n",
        "# Load the the dataset from raw image folders\n",
        "siamese_dataset = SiameseDataset(training_csv,training_dir,\n",
        "                                        transform=transforms.Compose([transforms.Resize((105,105)),\n",
        "                                                                      transforms.ToTensor()\n",
        "                                                                      ])\n",
        "                                       )\n",
        "\n",
        "# Load the dataset as pytorch tensors using dataloader\n",
        "train_dataloader = DataLoader(\n",
        "    siamese_dataset, shuffle=True, num_workers=8, batch_size=config.batch_size\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "\n",
        "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "\n",
        "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "        )\n",
        "        # Defining the fully connected layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(30976, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.5),\n",
        "\n",
        "            nn.Linear(1024, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(128,2))\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        # Forward pass\n",
        "        output = self.cnn(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # forward pass of input 1\n",
        "        output1 = self.forward_once(input1)\n",
        "        # forward pass of input 2\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "FJp8jaN0vfJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Contrastive loss function.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, x0, x1, y):\n",
        "        # euclidian distance\n",
        "        diff = x0 - x1\n",
        "        dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
        "        dist = torch.sqrt(dist_sq)\n",
        "\n",
        "        mdist = self.margin - dist\n",
        "        dist = torch.clamp(mdist, min=0.0)\n",
        "        loss = y * dist_sq + (1 - y) * torch.pow(dist, 2)\n",
        "        loss = torch.sum(loss) / 2.0 / x0.size()[0]\n",
        "        return loss"
      ],
      "metadata": {
        "id": "udlsdqS3vhqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare Siamese Network\n",
        "net = SiameseNetwork().cuda()\n",
        "# Decalre Loss Function\n",
        "criterion = ContrastiveLoss()\n",
        "# Declare Optimizer\n",
        "optimizer = th.optim.Adam(net.parameters(), lr=1e-3, weight_decay=0.0005)\n",
        "#train the model\n",
        "def train():\n",
        "    loss=[]\n",
        "    counter=[]\n",
        "    iteration_number = 0\n",
        "    for epoch in range(1,config.epochs):\n",
        "        for i, data in enumerate(train_dataloader,0):\n",
        "            img0, img1 , label = data\n",
        "            img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            output1,output2 = net(img0,img1)\n",
        "            loss_contrastive = criterion(output1,output2,label)\n",
        "            loss_contrastive.backward()\n",
        "            optimizer.step()\n",
        "        print(\"Epoch {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
        "        iteration_number += 10\n",
        "        counter.append(iteration_number)\n",
        "        loss.append(loss_contrastive.item())\n",
        "    show_plot(counter, loss)\n",
        "    return net\n",
        "#set the device to cuda\n",
        "device = torch.device('cuda' if th.cuda.is_available() else 'cpu')\n",
        "model = train()\n",
        "torch.save(model.state_dict(), \"output/model.pt\")\n",
        "print(\"Model Saved Successfully\")"
      ],
      "metadata": {
        "id": "m_0KPidcvjPt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}